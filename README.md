# Machine_learning_Projects
These are my Machine learning projects starting from the basics and moving further on to advanced level.

# Project 1 :
 Titanic Survival Exploration
 
• Created decision functions that attempt to predict survival outcomes from the 1912 Titanic disaster based on each passenger’s features, such as sex and age.<br>• Started with a simple algorithm and increased its complexity until I was able to accurately predict the outcomes for at least 80% of the passengers in the provided data. 


# Project 2 :
 Predicting Boston Housing Prices

• Built a model to predict the value of a given house in the Boston real estate market using various statistical analysis tools.<br>• Identified the best price that a client can sell their house utilizing machine learning.

# Project 3 :
 Building a Student Intervention System

• Investigated the factors that affect a student's performance in high school.<br> • Trained and tested several supervised machine learning models on a given dataset to predict how likely a student is to pass. <br>• Selected the best model based on relative accuracy and efficiency.

# Project 4 :
Creating Customer Segments

• Reviewed unstructured data to understand the patterns and natural categories that the data fits into. <br>• Used multiple algorithms and both empirically and theoretically compared and contrasted their results.<br>• Made predictions about the natural categories of multiple types in a dataset, then checked these predictions against the result of unsupervised analysis.

# Project 5 :
 Train a Smartcab How to Drive

• Applied reinforcement learning to build a simulated vehicle navigation agent. <br>• This project involved modeling a complex control problem in terms of limited available inputs, and designing a scheme to automatically learn an optimal driving strategy based on rewards and penalties.

# Project 6 :
Digit Recognizer

• Kaggle Competitions -https://www.kaggle.com/c/digit-recognizer<br>
• Task: Detect the written digits using data of various digits with labels from 0 - 10.<br>
• Applied Random Forest with variable number of estimators and analyed it's relation with the accuracy. <br>
• Another implementation involved using PCA and then KNN since KNN's are good for image realted problems.

# Project 7 :
Ghouls, Goblins, and Ghosts... Boo!

• Kaggle Competition - https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo<br>
• Task: to given features of creatures , classify them as Ghouls , Goblins & Ghosts.<br>
• Used PCA & Logistic Regression with Hyper Parameter Optimization with an added SVM model , similar to stacking.

# Project 8 :
Facial Keypoint Detection

• Kaggle Competition - https://www.kaggle.com/c/facial-keypoints-detection<br>
• Task: to detect the facial keypoints such as nose_tip , eye_center etc given images with around 15 labelled keypoints as data.<br>
• Applied CNN using librarires Lasagne & Theano and achieved 56th position on the leaderboard.
• Used Dropout and compared various Optimizers and even used Data Generation technique for scale,size & rotation invariance.

# Project 9:
House Prices: Advanced Regression Techniques

• Kaggle Competition - https://www.kaggle.com/c/house-prices-advanced-regression-techniques<br>
• Task: With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.

# Project 10:
Two Sigma Connect: Rental Listing Inquiries

• Kaggle Competition - https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries<br>
• Task: predict how popular an apartment rental listing is based on the listing content like text description, photos, number of bedrooms, price, etc. The data comes from renthop.com, an apartment listing website.

# Project 11:
March Machine Learning Mania 2017

• Kaggle Competition - https://www.kaggle.com/c/march-machine-learning-mania-2017<br>
Task:
• Stage 1 - You should submit predicted probabilities for every possible matchup in the past 4 NCAA tournaments (2013-2016).<br>
• Stage 2 - You should submit predicted probabilities for every possible matchup before the 2017 tournament begins.

# Project 12:
Two Sigma Financial Modeling Challenge

• Kaggle Competition - https://www.kaggle.com/c/two-sigma-financial-modeling<br>
Task:
• This dataset contains anonymized features pertaining to a time-varying value for a financial instrument.<br>• Each instrument has an id. Time is represented by the 'timestamp' feature and the variable to predict is 'y'.

# Project 13

• This Project is one of the Machine Learning Competitions on Hackerearth.<br>
• Link : https://www.hackerearth.com/challenge/competitive/machine-learning-challenge-one/ <br>
• The Bank Indessa has not done well in last 3 quarters. Their NPAs (Non Performing Assets) have reached all time high. It is starting to lose confidence of its investors. As a result, it’s stock has fallen by 20% in the previous quarter alone.

• After careful analysis, it was found that the majority of NPA was contributed by loan defaulters. With the messy data collected over all the years, this bank has decided to use machine learning to figure out a way to find these defaulters and devise a plan to reduce them.

• In this challenge, you will help this bank by predicting the probability that a member will default.

# Project 14

Indeed Machine Learning Codesprint hosted by Hackerrank<br>
• Link : - https://www.hackerrank.com/indeed-ml-codesprint-2017<br>
• Task: - Predicting Job tags with complete descriptions of jobs given.

# Project 15

Sberbank Russian Housing Market<br>

• Kaggle Competition : - https://www.kaggle.com/c/sberbank-russian-housing-market<br>
• Task : - Identify the Realty price fluctuations in Russia's volatile economy<br>
• Used : - Used Xgboost Model with hyper parameter optimization
