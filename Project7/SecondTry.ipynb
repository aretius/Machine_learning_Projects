{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amil Khare\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Done successfully !\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "sb.set_style(\"dark\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "# These are the imports necessary\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data  = pd.read_csv('test.csv')\n",
    "tlabel = train_data['type']\n",
    "print \"Done successfully !\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  bone_length  rotting_flesh  hair_length  has_soul  color    type\n",
      "0   0     0.354512       0.350839     0.465761  0.781142  clear   Ghoul\n",
      "1   1     0.575560       0.425868     0.531401  0.439899  green  Goblin\n"
     ]
    }
   ],
   "source": [
    "print train_data.head(2)\n",
    "train_data.describe()\n",
    "train_data = train_data.drop('type',1)\n",
    "train_data = train_data.drop('id',1)\n",
    "train_data = train_data.drop('color',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(clf, data, target, split_ratio):\n",
    "    trainX, testX, trainY, testY = train_test_split(data, target, train_size=split_ratio, random_state=0)\n",
    "    clf.fit(trainX, trainY)\n",
    "    return clf.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amil Khare\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Ghost       0.85      0.90      0.88        39\n",
      "      Ghoul       0.91      0.67      0.77        48\n",
      "     Goblin       0.47      0.68      0.56        25\n",
      "\n",
      "avg / total       0.79      0.75      0.76       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {'solver' : ('newton-cg', 'lbfgs', 'liblinear', 'sag'), 'C':[1,10,50,100,500,1000,5000,10000,50000,100000,500000,1000000,5000000]}\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(train_data,tlabel,test_size = 0.3,random_state=0)\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr,param)\n",
    "clf.fit(x_train,y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(classification_report(pred,y_test))\n",
    "\n",
    "\n",
    "# print pred\n",
    "\n",
    "# print y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amil Khare\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Ghost       0.76      0.78      0.77        40\n",
      "      Ghoul       0.74      0.59      0.66        44\n",
      "     Goblin       0.42      0.54      0.47        28\n",
      "\n",
      "avg / total       0.67      0.64      0.65       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF\n",
    "param2 = { 'n_estimators':[1,5,10,50,100,150,350,500,750,1000,1500,2000,2500,5000,7500,10000],'oob_score':('True','False'),'criterion':('gini','entropy')}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "clf2 = GridSearchCV(rf,param2)\n",
    "clf2.fit(x_train,y_train)\n",
    "pred2 = clf2.predict(x_test)\n",
    "print(classification_report(pred2,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param3 = {'kernel':('rbf','poly','linear','sigmoid'),'degree':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,25,30,35,40,50],'C':[0.000001,0.00001,0.001,0.0001,0.01,1,10,100,1000,10000],'probability':[True,False]}\n",
    "\n",
    "svm =SVC(max_iter=-1)\n",
    "clf3 = GridSearchCV(svm,param3)\n",
    "clf3.fit(x_train,y_train)\n",
    "pred3 = clf3.predict(x_test)\n",
    "print(classification_report(pred3,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test_index = test_data['id']\n",
    "test_data.drop('id',1,inplace=True)\n",
    "test_data.drop('color',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_pred = clf2.predict(test_data)\n",
    "\n",
    "sol = pd.DataFrame()\n",
    "sol[\"id\"] = test_index\n",
    "sol[\"type\"] = final_pred\n",
    "sol.to_csv(\"submission.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
